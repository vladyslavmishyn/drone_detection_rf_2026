{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314a7ab2",
   "metadata": {},
   "source": [
    "# Drone RF Dataset\n",
    "\n",
    "This notebook builds a **drone-only RF dataset** from two public UAV datasets:\n",
    "\n",
    "1. **AirID**  \n",
    "   - Format: `.mat`\n",
    "   - Content: raw IQ samples of UAV transmissions with RF impairments\n",
    "\n",
    "2. **Hovering UAVs RF Fingerprinting Dataset**\n",
    "   - Format: `.bin` + `.json` (SigMF)\n",
    "   - Content: raw IQ samples of hovering DJI M100 UAVs\n",
    "\n",
    "we randomly sample both of them because there are too many files\n",
    "\n",
    "The output is a **master dataset** of overlapping windows stored as `.npz` files.\n",
    "\n",
    "I uploaded these two datasets and the  to google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4c64e",
   "metadata": {},
   "source": [
    "#### Master Dataset Format\n",
    "\n",
    "Each sample is stored as a `.npz` file with:\n",
    "\n",
    "- `x` : spectrogram (float32, shape = [freq_bins, time_bins])\n",
    "- `y` : label (1 = drone)\n",
    "- `meta` : metadata (dataset source, sample rate, center frequency)\n",
    "\n",
    "\n",
    "in the end we get approx 6k windows from each dataset with random sampling (takes around 500 MB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33b1c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.signal import stft\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ae3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windowing\n",
    "WINDOW_SAMPLES = 4096\n",
    "HOP_SAMPLES = 2048\n",
    "\n",
    "# Spectrogram\n",
    "NFFT = 512\n",
    "\n",
    "# Output\n",
    "OUT_DIR = \"drone_dataset_npz\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68652212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_iq(iq):\n",
    "    \"\"\"Power normalize IQ samples\"\"\"\n",
    "    return iq / np.sqrt(np.mean(np.abs(iq)**2) + 1e-12)\n",
    "\n",
    "\n",
    "def iq_to_spectrogram(iq, fs):\n",
    "    \"\"\"Convert IQ window to log-magnitude spectrogram\"\"\"\n",
    "    f, t, Z = stft(iq, fs=fs, nperseg=NFFT, noverlap=NFFT//2)\n",
    "    spec = np.log1p(np.abs(Z))\n",
    "    return spec.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_iq_from_mat(mat):\n",
    "    for k, v in mat.items():\n",
    "        if isinstance(v, np.ndarray) and np.iscomplexobj(v):\n",
    "            return v.flatten()\n",
    "        if isinstance(v, np.ndarray) and v.ndim == 1:\n",
    "            return v.flatten()\n",
    "    return None\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "def process_airid_root(root_dir, out_dir):\n",
    "    mat_files = []\n",
    "\n",
    "    for root, _, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            if f.endswith(\".mat\"):\n",
    "                mat_files.append(os.path.join(root, f))\n",
    "\n",
    "    print(f\"[AirID] Found {len(mat_files)} .mat files\")\n",
    "\n",
    "    files_processed = 0\n",
    "    total_windows = 0\n",
    "    kept_windows = 0\n",
    "    WINDOW_KEEP_PROB = 1/30\n",
    "\n",
    "    pbar = tqdm(mat_files, desc=\"AirID files\", leave=True)\n",
    "\n",
    "    for path in pbar:\n",
    "        try:\n",
    "            mat = sio.loadmat(path)\n",
    "            iq = extract_iq_from_mat(mat)\n",
    "\n",
    "            if iq is None:\n",
    "                pbar.set_postfix(status=\"no IQ\")\n",
    "                continue\n",
    "\n",
    "            files_processed += 1\n",
    "            iq = normalize_iq(iq)\n",
    "            fs = 10e6\n",
    "\n",
    "            win_count = 0\n",
    "            kept_count = 0\n",
    "\n",
    "            for start in range(0, len(iq) - WINDOW_SAMPLES, HOP_SAMPLES):\n",
    "                total_windows += 1\n",
    "\n",
    "                if random.random() > WINDOW_KEEP_PROB:\n",
    "                    continue\n",
    "\n",
    "                window = iq[start:start + WINDOW_SAMPLES]\n",
    "                spec = iq_to_spectrogram(window, fs)\n",
    "\n",
    "                np.savez(\n",
    "                    os.path.join(out_dir, f\"airid_{kept_windows}.npz\"),\n",
    "                    x=spec,\n",
    "                    y=1,\n",
    "                    meta={\n",
    "                        \"dataset\": \"AirID\",\n",
    "                        \"source_file\": path,\n",
    "                        \"fs\": fs\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                kept_windows += 1\n",
    "                kept_count += 1\n",
    "                win_count += 1\n",
    "\n",
    "            pbar.set_description(f\"AirID ({os.path.basename(path)})\")\n",
    "            pbar.set_postfix(\n",
    "                files=files_processed,\n",
    "                total_windows_seen=total_windows,\n",
    "                windows_kept=kept_windows,\n",
    "                kept_this_file=kept_count\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            pbar.set_postfix(error=str(e))\n",
    "\n",
    "    print(\n",
    "        f\"[AirID] Done | \"\n",
    "        f\"Files processed: {files_processed}/{len(mat_files)} | \"\n",
    "        f\"Total windows seen: {total_windows} | \"\n",
    "        f\"Windows kept: {kept_windows}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dfb1d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sigmf_iq(bin_path, json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "\n",
    "    fs = meta[\"global\"][\"core:sample_rate\"]\n",
    "    fc = meta[\"captures\"][\"core:center_frequency\"]\n",
    "\n",
    "    raw = np.fromfile(bin_path, dtype=np.float16)\n",
    "    iq = raw[0::2] + 1j * raw[1::2]\n",
    "    iq = normalize_iq(iq)\n",
    "\n",
    "    return iq, fs, fc\n",
    "\n",
    "def parse_hover_filename(fname):\n",
    "    parts = fname.replace(\".bin\", \"\").split(\"_\")\n",
    "    return {\n",
    "        \"uav\": parts[0], \n",
    "        \"distance\": parts[1],\n",
    "        \"burst\": parts[2],\n",
    "    }\n",
    "\n",
    "def process_hovering_root(root_dir, out_dir):\n",
    "    bin_files = [f for f in os.listdir(root_dir) if f.endswith(\".bin\")]\n",
    "\n",
    "    from collections import defaultdict\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "\n",
    "    for f in bin_files:\n",
    "        info = parse_hover_filename(f)\n",
    "        key = (info[\"uav\"], info[\"distance\"])\n",
    "        groups[key].append(f)\n",
    "\n",
    "        #print(f\"[HoveringUAV] Found {len(bin_files)} .bin files\")\n",
    "    \n",
    "    #print(len(groups), \"groups found\")\n",
    "\n",
    "    import random\n",
    "\n",
    "    MAX_FILES_PER_GROUP = 5\n",
    "\n",
    "    sampled_files = []\n",
    "\n",
    "    for key, files in groups.items():\n",
    "        sampled = random.sample(files, min(MAX_FILES_PER_GROUP, len(files)))\n",
    "        sampled_files.extend(sampled)\n",
    "\n",
    "    files_processed = 0\n",
    "    total_windows = 0\n",
    "\n",
    "    print(f\"[HoveringUAV] Samples {len(sampled_files)} .bin files\")\n",
    "\n",
    "    pbar = tqdm(sampled_files, desc=\"Sampled hovering UAV files\", leave=True)\n",
    "\n",
    "    for f in pbar:\n",
    "        bin_path = os.path.join(root_dir, f)\n",
    "        json_path = bin_path.replace(\".bin\", \".json\")\n",
    "\n",
    "        if not os.path.exists(json_path):\n",
    "            pbar.set_postfix(status=\"missing json\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            iq, fs, fc = load_sigmf_iq(bin_path, json_path)\n",
    "            files_processed += 1\n",
    "\n",
    "            win_count = 0\n",
    "            for start in range(0, len(iq) - WINDOW_SAMPLES, HOP_SAMPLES):\n",
    "                window = iq[start:start + WINDOW_SAMPLES]\n",
    "                spec = iq_to_spectrogram(window, fs)\n",
    "\n",
    "                np.savez(\n",
    "                    os.path.join(out_dir, f\"hover_{total_windows}.npz\"),\n",
    "                    x=spec,\n",
    "                    y=1,\n",
    "                    meta={\n",
    "                        \"dataset\": \"HoveringUAV\",\n",
    "                        \"source_file\": bin_path,\n",
    "                        \"fs\": fs,\n",
    "                        \"fc\": fc\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                total_windows += 1\n",
    "                win_count += 1\n",
    "\n",
    "            # Update progress bar text instead of printing\n",
    "            pbar.set_description(f\"Hovering UAV ({f})\")\n",
    "            pbar.set_postfix(\n",
    "                files=files_processed,\n",
    "                windows=total_windows,\n",
    "                last_file_windows=win_count\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            pbar.set_postfix(error=str(e))\n",
    "\n",
    "    print(\n",
    "        f\"[HoveringUAV] Done | \"\n",
    "        f\"Files processed: {files_processed}/{len(bin_files)} | \"\n",
    "        f\"Windows created: {total_windows}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1f642fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AirID] Found 102 .mat files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AirID files:   0%|          | 0/102 [00:00<?, ?it/s]/var/folders/yn/6g9xs7712r5_hqwt4w9dvbg80000gp/T/ipykernel_19072/392685162.py:8: UserWarning: Input data is complex, switching to return_onesided=False\n",
      "  f, t, Z = stft(iq, fs=fs, nperseg=NFFT, noverlap=NFFT//2)\n",
      "AirID (WiFiRxKRI_air_radio2_amp_2_ph_0_CBW5_MCS3.mat): 100%|██████████| 102/102 [00:33<00:00,  3.01it/s, files=102, kept_this_file=256, total_windows_seen=182060, windows_kept=6025]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AirID] Done | Files processed: 102/102 | Total windows seen: 182060 | Windows kept: 6025\n",
      "[HoveringUAV] Samples 136 .bin files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hovering UAV (uav7_15ft_burst2_1.bin): 100%|██████████| 136/136 [00:04<00:00, 30.55it/s, files=136, last_file_windows=8, windows=5647]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HoveringUAV] Done | Files processed: 136/13893 | Windows created: 5647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "AIRID_ROOT = \"drone_datasets/AirID-Globecom2020_dataset\"\n",
    "HOVER_ROOT = \"drone_datasets/UAV-Sigmf-float16\"\n",
    "\n",
    "process_airid_root(AIRID_ROOT, OUT_DIR)\n",
    "process_hovering_root(HOVER_ROOT, OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
